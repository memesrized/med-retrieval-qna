{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-28 19:24:49,163 - mrq.aug - INFO - Initial number of examples: 23\n",
      "2023-05-28 19:24:49,165 - mrq.aug - INFO - Result number (before set) of examples: 138\n",
      "2023-05-28 19:24:49,165 - mrq.aug - INFO - Epoch 0 of 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21e631888ed4bc2b877ad912c2c39c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My very relevant sentence.', 'Great lately, enjoy some much needed downtime and explore new hobbies.', 'And another one', \"However my world has lately been quite hectic, but fortunately I'm managed to stay focused.\", 'It has been stimulating my brain with some interesting projects lately.', 'To be honest, I have been feeling some very stressed, but now I am addressing it.']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from mrq.aug import Augmentator, Paraphraser, augment_init_data\n",
    "from mrq.logger import get_logger\n",
    "\n",
    "log = get_logger(__name__)\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "paraphraser = Paraphraser(device=device)\n",
    "\n",
    "augs = augment_init_data(\n",
    "    \"aug_init_data.json\",\n",
    "    \"test_models_augmentation.json\",\n",
    "    epochs=3,\n",
    "    paraphraser=paraphraser,\n",
    "    return_=True,\n",
    "    num_seq=6\n",
    ")\n",
    "augmenter = Augmentator(augs, aug_num=4)\n",
    "# smoke test\n",
    "print(augmenter(\"My very relevant sentence. And another one\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from mrq import PROJECT_PATHS\n",
    "from mrq.algs import GoldenRetriever\n",
    "from mrq.aug import Augmentator\n",
    "from mrq.data import AnswerDB, Query, load_data\n",
    "from mrq.logger import get_logger\n",
    "from mrq.models import EmbedModel, NERClassifier\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "log = get_logger(__name__)\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_len = 10\n",
    "\n",
    "ner_models = [\n",
    "    \"ukkendane/bert-medical-ner\",\n",
    "    \"samrawal/bert-base-uncased_clinical-ner\",\n",
    "    \"samrawal/bert-large-uncased_med-ner\",\n",
    "]\n",
    "emb_models = [\n",
    "    \"emilyalsentzer/Bio_ClinicalBERT\",\n",
    "    \"medicalai/ClinicalBERT\",\n",
    "    \"pritamdeka/S-Biomed-Roberta-snli-multinli-stsb\",\n",
    "    \"menadsa/S-BioELECTRA\",\n",
    "    \"TimKond/S-BioLinkBert-MedQuAD\",\n",
    "    \"TimKond/S-PubMedBert-MedQuAD\",\n",
    "    \"kamalkraj/bioelectra-base-discriminator-pubmed\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "seed = 1337\n",
    "\n",
    "data = load_data(\"medmcqa\", sample_size=sample_size, seed=seed)\n",
    "data1 = load_data(\"AnonymousSub/MedQuAD_47441_Question_Answer_Pairs\", sample_size=sample_size, seed=seed)\n",
    "\n",
    "data = data.append(data1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenter = Augmentator(PROJECT_PATHS.data / \"test_models_augmentation.json\", aug_num=4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's better to rewrite it with matrix multiplication, but I had to spend time for service itself and it's wrappers, so it's very straight forward implementation with cycles."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=[\"embeddings\", \"ner\", \"scores\"])\n",
    "\n",
    "for i_emb, emb in enumerate(emb_models):\n",
    "    log.info(\n",
    "        \"Starting process for {0} embedding model, {1}/{2}\".format(\n",
    "            emb, i_emb, len(emb_models)\n",
    "        )\n",
    "    )\n",
    "    emb_model = EmbedModel(emb, device=device)\n",
    "\n",
    "    # data preparation\n",
    "    augmented_questions = data[\"Q\"].map(augmenter)\n",
    "    answers = AnswerDB(data[\"A\"].tolist()).encode(\n",
    "        emb=emb_model, tqdm_flag=True, batch_len=batch_len\n",
    "    )\n",
    "    retriever = GoldenRetriever(answers)\n",
    "    log.info(\"All answers encoded\")\n",
    "    # emb_model._model.to(\"cpu\")\n",
    "    # emb_model.device = \"cpu\"\n",
    "    for i_ner, ner in enumerate(ner_models):\n",
    "        log.info(\"Processing {0} model, {1}/{2}\".format(ner, i_ner, len(ner_models)))\n",
    "\n",
    "        ner_model = NERClassifier(ner, device=device)\n",
    "\n",
    "        questions_extracted = augmented_questions.map(ner_model.extract).map(\n",
    "            lambda x: \" \".join(x)\n",
    "        )\n",
    "        questions = AnswerDB(questions_extracted.tolist()).encode(\n",
    "            emb=emb_model, tqdm_flag=True, batch_len=batch_len\n",
    "        )\n",
    "        # this is bad, but AnswerDB refactoring is required otherwise\n",
    "        for i_q in tqdm(range(len(questions)), desc=\"query\"):\n",
    "            q = Query(text=questions.data[i_q], embedded=questions.embedded[i_q])\n",
    "            res = retriever.find_it(q=q)\n",
    "            break\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approx pipeline:\n",
    "\n",
    "1. augment data input \n",
    "2. ner classifier\n",
    "3. query\n",
    "4. embeddings\n",
    "5. retrieval model\n",
    "6. score\n",
    "\n",
    "\n",
    "retrieval -> sorted indices (+ real answer from the start)-> score -> top_n or mean/median position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[145,  12,  10],\n",
       "        [145,  12,  10]]),\n",
       "indices=tensor([[3, 2, 0],\n",
       "        [3, 2, 0]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([[10,2,12,145,1], [10,2,12,145,1]])\n",
    "x\n",
    "torch.topk(x, 3, sorted=True, largest=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomapas",
   "language": "python",
   "name": "biomapas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
