{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spoiler:\n",
    "\n",
    "Small LLMs are bad for new similar phrases generation and it's time consuming prompting, so  I decided to use good old T5 paraphraser and created initial set of sentences that person can say in conversation occasionally (e.g. answer to how are you). \n",
    "\n",
    "Some examples were generated with ChatGPT, some with me =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from mrq import PROJECT_PATHS\n",
    "\n",
    "with open(PROJECT_PATHS.init_data / \"aug_init_data.json\") as file:\n",
    "    shots = json.load(file)\n",
    "\n",
    "LLM_FLAG = False # change to play with small LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LLM_FLAG:\n",
    "    import numpy as np\n",
    "    from transformers import GPTNeoXForCausalLM, AutoTokenizer\n",
    "\n",
    "    gen_model = GPTNeoXForCausalLM.from_pretrained(\"EleutherAI/pythia-410m\")\n",
    "    gen_tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-410m\")\n",
    "\n",
    "    # As this model is not fine-tuned to follow instructions,\n",
    "    # let's try to use is just as text generation with few-shot prompts\n",
    "    # based on previously generated inputs from curated list\n",
    "    n_shots = 9\n",
    "\n",
    "    pre = f\"{n_shots+1} examples of replies to 'How are you doing':\\n\\n\"\n",
    "\n",
    "    conv = \"\\n\".join([f\"{i}. \"+x for i, x in enumerate(np.random.choice(shots, n_shots, replace=False), 1)])\n",
    "    conv+=f\"\\n{n_shots+1} \"\n",
    "\n",
    "    text = pre+conv\n",
    "    # text = conv\n",
    "\n",
    "    tokens = gen_model.generate(\n",
    "        **gen_tokenizer(text, return_tensors=\"pt\"),\n",
    "        top_p=15,\n",
    "        # top_k=20,\n",
    "        # num_beams=5,\n",
    "        temperature=0.3,\n",
    "        do_sample=True,\n",
    "        num_return_sequences=3,\n",
    "        max_new_tokens=35,\n",
    "        repetition_penalty=5.0,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    for x in tokens:\n",
    "        print(gen_tokenizer.decode(x))\n",
    "        print(\"-\" * 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T5 for augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I felt great in the last year, enjoying some much-needed downtime, and finding new hobbies to explore.',\n",
       " 'I am currently excellently enjoying some much needed time off and exploring new hobbies.',\n",
       " \"I've felt in my last week well: enjoying some much-needed recovery times and exploring new hobbies (Turning Sprockets! )!\",\n",
       " \"I've been amazing lately having some much-needed downtime and exploring new hobbyry.\",\n",
       " 'Recent times have been great, enjoying some much-needed down time and exploring new skills.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from mrq import PROJECT_PATHS\n",
    "from mrq.aug import Paraphraser\n",
    "\n",
    "with open(PROJECT_PATHS.init_data / \"aug_init_data.json\") as file:\n",
    "    shots = json.load(file)\n",
    "\n",
    "device = \"cpu\"\n",
    "paraphraser = Paraphraser(device=device)\n",
    "\n",
    "text = \"paraphrase: \" + shots[0] + \" </s>\"\n",
    "paraphraser(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from mrq.aug import Augmentator, augment_init_data\n",
    "from mrq.logger import get_logger\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "log = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-28 17:34:16,665 - mrq.aug - INFO - Initial number of examples: 23\n",
      "2023-05-28 17:34:16,665 - mrq.aug - INFO - Result number (before set) of examples: 138\n",
      "2023-05-28 17:34:16,666 - mrq.aug - INFO - Epoch 0 of 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654cc9d822db4817bcc8c33bc107686b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aug = augment_init_data(\n",
    "    \"aug_init_data.json\",\n",
    "    \"examples_for_augmentation.json\",\n",
    "    paraphraser=paraphraser,\n",
    "    return_=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenter = Augmentator(aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['And another one',\n",
       " 'Recently I have kept busy with some interesting projects, feeling motivated.',\n",
       " 'Like usual. But because this is far too important, I am trying my best to try to balance this.',\n",
       " 'My very relevant sentence.',\n",
       " 'So this guy still lacked ambition to play and just finished up this lovely book.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmenter(\"My very relevant sentence. And another one\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomapas",
   "language": "python",
   "name": "biomapas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
